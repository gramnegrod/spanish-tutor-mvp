<!DOCTYPE html>
<html>
<head>
    <title>OpenAI Realtime API - WebRTC</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 50px auto;
            padding: 20px;
            background: #f5f5f5;
        }
        .container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        button {
            padding: 12px 24px;
            font-size: 16px;
            margin: 10px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            color: white;
        }
        #connectBtn { background: #4CAF50; }
        #connectBtn:hover { background: #45a049; }
        #connectBtn:disabled { background: #ccc; cursor: not-allowed; }
        
        #messages {
            border: 1px solid #ddd;
            padding: 20px;
            height: 400px;
            overflow-y: auto;
            margin: 20px 0;
            background: #f9f9f9;
            border-radius: 5px;
        }
        .message {
            margin: 10px 0;
            padding: 10px;
            border-radius: 5px;
        }
        .user { 
            background: #e3f2fd; 
            margin-left: 50px;
            text-align: right;
        }
        .assistant { 
            background: #f5f5f5; 
            margin-right: 50px;
            border: 1px solid #ddd;
        }
        .status {
            padding: 10px;
            background: #fff3cd;
            border: 1px solid #ffeaa7;
            border-radius: 5px;
            margin: 10px 0;
        }
        .error {
            background: #f8d7da;
            border: 1px solid #f5c6cb;
            color: #721c24;
        }
        
        /* Speaking indicator */
        .speaking-indicator {
            display: none;
            align-items: center;
            justify-content: center;
            margin: 20px 0;
            padding: 15px;
            background: #e3f2fd;
            border-radius: 10px;
            gap: 10px;
        }
        
        .speaking-indicator.active {
            display: flex;
        }
        
        .speaking-dot {
            width: 8px;
            height: 8px;
            background: #2196F3;
            border-radius: 50%;
            animation: pulse 1.4s infinite;
        }
        
        .speaking-dot:nth-child(2) { animation-delay: 0.2s; }
        .speaking-dot:nth-child(3) { animation-delay: 0.4s; }
        
        @keyframes pulse {
            0%, 60%, 100% {
                transform: scale(1);
                opacity: 1;
            }
            30% {
                transform: scale(1.5);
                opacity: 0.7;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è OpenAI Realtime API - WebRTC Demo</h1>
        <p>Talk to a Mexican Spanish Tutor using WebRTC</p>
        
        <div id="status" class="status">Ready to connect</div>
        
        <button id="connectBtn" onclick="connectToOpenAI()">Connect & Start Talking</button>
        <button id="disconnectBtn" onclick="disconnect()" style="display: none; background: #f44336;">Disconnect</button>
        
        <div class="speaking-indicator" id="speakingIndicator">
            <div class="speaking-dot"></div>
            <div class="speaking-dot"></div>
            <div class="speaking-dot"></div>
            <span>Listening to you...</span>
        </div>
        
        <div id="messages">
            <div style="color: #666; text-align: center;">Messages will appear here...</div>
        </div>
        
        <audio id="audioElement" autoplay></audio>
    </div>

    <script>
        let pc = null;
        let dc = null;
        let mediaStream = null;
        
        function updateStatus(message, isError = false) {
            const statusDiv = document.getElementById('status');
            statusDiv.textContent = message;
            statusDiv.className = isError ? 'status error' : 'status';
        }
        
        function addMessage(role, text) {
            const messagesDiv = document.getElementById('messages');
            if (messagesDiv.firstChild && messagesDiv.firstChild.style && messagesDiv.firstChild.style.color === '#666') {
                messagesDiv.innerHTML = '';
            }
            
            const messageDiv = document.createElement('div');
            messageDiv.className = 'message ' + role;
            messageDiv.textContent = text;
            messagesDiv.appendChild(messageDiv);
            messagesDiv.scrollTop = messagesDiv.scrollHeight;
        }
        
        async function connectToOpenAI() {
            const button = document.getElementById('connectBtn');
            button.disabled = true;
            updateStatus('Getting ephemeral key...');
            
            try {
                // Step 1: Get ephemeral key from our server
                const tokenResponse = await fetch('/api/session');
                if (!tokenResponse.ok) {
                    throw new Error(`Server error: ${tokenResponse.status}`);
                }
                
                const data = await tokenResponse.json();
                if (!data.client_secret || !data.client_secret.value) {
                    throw new Error('No client secret received');
                }
                
                const EPHEMERAL_KEY = data.client_secret.value;
                updateStatus('Got key, creating connection...');
                
                // Step 2: Create peer connection
                pc = new RTCPeerConnection();
                
                // Step 3: Set up audio playback
                const audioEl = document.getElementById('audioElement');
                pc.ontrack = e => {
                    console.log('Received audio track');
                    audioEl.srcObject = e.streams[0];
                };
                
                // Step 4: Add microphone
                updateStatus('Requesting microphone access...');
                mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                pc.addTrack(mediaStream.getTracks()[0]);
                
                // Step 5: Create data channel for events
                dc = pc.createDataChannel('oai-events');
                
                dc.onopen = () => {
                    updateStatus('Connected! Speak in English or Spanish');
                    
                    // Configure the session
                    dc.send(JSON.stringify({
                        type: 'session.update',
                        session: {
                            modalities: ['text', 'audio'],
                            instructions: 'You are a friendly Mexican taco vendor (taquero). Speak only in Mexican Spanish. Use casual expressions like "¬°√ìrale!", "¬øQu√© onda?", "¬°√Åndale!". Be warm and helpful.',
                            voice: 'alloy',
                            input_audio_format: 'pcm16',
                            output_audio_format: 'pcm16',
                            // Removed input_audio_transcription for better UX
                            turn_detection: {
                                type: 'server_vad',
                                threshold: 0.5,
                                prefix_padding_ms: 300,
                                silence_duration_ms: 200
                            },
                            temperature: 0.8
                        }
                    }));
                };
                
                dc.onmessage = (e) => {
                    const event = JSON.parse(e.data);
                    console.log('Event:', event.type);
                    
                    // Handle different event types
                    switch(event.type) {
                        case 'error':
                            console.error('Error:', event.error);
                            updateStatus(`Error: ${event.error.message}`, true);
                            break;
                            
                        case 'session.created':
                        case 'session.updated':
                            console.log('Session ready');
                            break;
                            
                        case 'input_audio_buffer.speech_started':
                            updateStatus('Listening...');
                            document.getElementById('speakingIndicator').classList.add('active');
                            break;
                            
                        case 'input_audio_buffer.speech_stopped':
                            updateStatus('Processing...');
                            document.getElementById('speakingIndicator').classList.remove('active');
                            break;
                            
                        // User transcription removed for better UX
                            
                        case 'response.audio_transcript.done':
                            addMessage('assistant', event.transcript);
                            updateStatus('Ready - Speak anytime');
                            break;
                            
                        case 'response.done':
                            updateStatus('Ready - Speak anytime');
                            document.getElementById('speakingIndicator').classList.remove('active');
                            break;
                    }
                };
                
                dc.onerror = (error) => {
                    console.error('Data channel error:', error);
                    updateStatus('Data channel error', true);
                };
                
                // Step 6: Create and send offer
                updateStatus('Creating connection offer...');
                const offer = await pc.createOffer();
                await pc.setLocalDescription(offer);
                
                // Step 7: Send offer to OpenAI
                updateStatus('Connecting to OpenAI...');
                const baseUrl = 'https://api.openai.com/v1/realtime';
                const model = 'gpt-4o-realtime-preview-2024-12-17';
                
                const sdpResponse = await fetch(`${baseUrl}?model=${model}`, {
                    method: 'POST',
                    body: offer.sdp,
                    headers: {
                        'Authorization': `Bearer ${EPHEMERAL_KEY}`,
                        'Content-Type': 'application/sdp'
                    }
                });
                
                if (!sdpResponse.ok) {
                    const error = await sdpResponse.text();
                    throw new Error(`OpenAI error: ${sdpResponse.status} - ${error}`);
                }
                
                // Step 8: Set remote description
                const answer = {
                    type: 'answer',
                    sdp: await sdpResponse.text()
                };
                await pc.setRemoteDescription(answer);
                
                updateStatus('Connected! Waiting for audio...');
                
                // Show disconnect button, hide connect button
                document.getElementById('connectBtn').style.display = 'none';
                document.getElementById('disconnectBtn').style.display = 'inline-block';
                
            } catch (error) {
                console.error('Connection error:', error);
                updateStatus(`Error: ${error.message}`, true);
                button.disabled = false;
            }
        }
        
        function disconnect() {
            // Stop media stream
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
            
            // Close data channel
            if (dc) {
                dc.close();
                dc = null;
            }
            
            // Close peer connection
            if (pc) {
                pc.close();
                pc = null;
            }
            
            // Stop audio playback
            const audioEl = document.getElementById('audioElement');
            audioEl.srcObject = null;
            
            // Update UI
            updateStatus('Disconnected');
            document.getElementById('speakingIndicator').classList.remove('active');
            document.getElementById('connectBtn').style.display = 'inline-block';
            document.getElementById('connectBtn').disabled = false;
            document.getElementById('disconnectBtn').style.display = 'none';
            
            // Clear messages
            document.getElementById('messages').innerHTML = '<div style="color: #666; text-align: center;">Messages will appear here...</div>';
        }
    </script>
</body>
</html>