# OpenAI Realtime API: WebRTC Implementation Guide & Learnings

## Key Discovery: WebRTC vs WebSocket

### ❌ What Doesn't Work: WebSocket Approach
Initially attempted to connect using WebSocket directly from the browser:
- **Error**: "Missing bearer or basic authentication in header"
- **Root Cause**: Browsers cannot set custom headers on WebSocket connections
- **Security Issue**: Would require exposing API key in client-side code

### ✅ What Works: WebRTC Approach
OpenAI's Realtime API uses WebRTC for browser connections:
- **Ephemeral Keys**: Server generates temporary tokens for client use
- **Native Browser Support**: WebRTC is designed for real-time communication
- **Secure**: API key stays on server, client uses temporary token

## Architecture Overview

```
┌─────────────┐     ┌──────────────┐     ┌─────────────────┐
│   Browser   │────▶│  Your Server │────▶│  OpenAI API     │
│  (WebRTC)   │◀────│ (Ephemeral   │◀────│ (Session Token) │
└─────────────┘     │   Key Gen)   │     └─────────────────┘
                    └──────────────┘
```

## Implementation Steps

### 1. Server-Side: Ephemeral Key Generation
```typescript
// /api/session/route.ts
const response = await fetch("https://api.openai.com/v1/realtime/sessions", {
  method: "POST",
  headers: {
    "Authorization": `Bearer ${process.env.OPENAI_API_KEY}`,
    "Content-Type": "application/json",
  },
  body: JSON.stringify({
    model: "gpt-4o-realtime-preview-2024-12-17",
    voice: "alloy", // or "verse"
  }),
});

// Returns: { client_secret: { value: "ek_..." } }
```

### 2. Client-Side: WebRTC Connection
```javascript
// 1. Get ephemeral key from your server
const tokenResponse = await fetch('/api/session');
const { client_secret: { value: EPHEMERAL_KEY } } = await tokenResponse.json();

// 2. Create peer connection and data channel
const pc = new RTCPeerConnection();
const dc = pc.createDataChannel('oai-events');

// 3. Add microphone
const ms = await navigator.mediaDevices.getUserMedia({ audio: true });
pc.addTrack(ms.getTracks()[0]);

// 4. Create offer and connect
const offer = await pc.createOffer();
await pc.setLocalDescription(offer);

const sdpResponse = await fetch(
  `https://api.openai.com/v1/realtime?model=${model}`, 
  {
    method: 'POST',
    body: offer.sdp,
    headers: {
      'Authorization': `Bearer ${EPHEMERAL_KEY}`,
      'Content-Type': 'application/sdp'
    }
  }
);

await pc.setRemoteDescription({
  type: 'answer',
  sdp: await sdpResponse.text()
});
```

## Critical Learnings

### 1. Audio Transcription Issues
- **Problem**: Whisper transcription often incorrect for multilingual conversations
- **Discovery**: The AI understands audio perfectly without transcription
- **Solution**: Remove `input_audio_transcription` for better UX

### 2. Native Model Transcription
- **Output Transcription**: Generated natively by the model (accurate)
- **Input Transcription**: Generated by separate Whisper model (less accurate)
- **Key Events**:
  - `response.audio_transcript.delta` - Streaming assistant text
  - `response.audio_transcript.done` - Complete assistant message

### 3. Session Configuration Best Practices
```javascript
{
  type: 'session.update',
  session: {
    modalities: ['text', 'audio'],
    voice: 'alloy',
    input_audio_format: 'pcm16',
    output_audio_format: 'pcm16',
    // Omit input_audio_transcription for auto-detection
    turn_detection: {
      type: 'server_vad',
      threshold: 0.5,
      prefix_padding_ms: 300,
      silence_duration_ms: 200
    },
    temperature: 0.8
  }
}
```

### 4. Event Flow Understanding
1. User speaks → `input_audio_buffer.speech_started`
2. User stops → `input_audio_buffer.speech_stopped`
3. Server processes → `response.created`
4. AI responds → `response.audio_transcript.delta/done`
5. Audio plays → Through WebRTC audio track

## Common Pitfalls to Avoid

1. **Don't use WebSocket from browsers** - Use WebRTC
2. **Don't expose API keys** - Use ephemeral tokens
3. **Don't rely on Whisper for multilingual** - Trust the model's understanding
4. **Don't set language to `null`** - Omit parameter for auto-detection
5. **Don't forget cleanup** - Stop streams and close connections

## Security Considerations

- **API Key**: Never expose in client code
- **Ephemeral Keys**: Short-lived, limited scope
- **CORS**: Server endpoint needed for token generation
- **Audio Permissions**: Always request user consent

## Future Improvements

1. **Token Refresh**: Implement automatic renewal for long sessions
2. **Reconnection**: Handle network interruptions gracefully
3. **Audio Visualization**: Show waveforms or volume levels
4. **Session History**: Store conversation transcripts
5. **Multi-language UI**: Detect and adapt to user's language

## Resources

- [OpenAI Realtime API Docs](https://platform.openai.com/docs/guides/realtime)
- [WebRTC MDN Documentation](https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API)
- [Session Description Protocol (SDP)](https://datatracker.ietf.org/doc/html/rfc4566)